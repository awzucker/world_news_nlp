{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World News NLP Project: Notebook 1\n",
    "## EDA, Data Processing & Feature Engineering\n",
    "#### Adam Zucker\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Using industry-standard NLP libraries [SpaCy](https://spacy.io/), [NLTK](https://www.nltk.org/), and [scikit-learn](https://scikit-learn.org/stable/), this study will examine the key words in a post title that most positively affect user engagement. The exploratory data analysis and visualizations in the following notebook will also factor in other features of the supplied data, including author, post time, and date. For the purposes of this study, positive user engagement will be measured in upvotes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Contents\n",
    "\n",
    "1. Library and Data Imports\n",
    "2. Basic Exploratory Data Analysis\n",
    "3. Data Visualizations\n",
    "4. NLP\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "- __*world_news_posts.csv*:__ Supplied dataframe with roughly 500,000 titles of posts on a \"world news\" message board, including data for the date, time, and author of the post, along with user interaction.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "df = pd.read_csv('../data/world_news_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>date_created</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>over_18</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201232046</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1201232075</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan resumes refuelling mission</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201232523</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>US presses Egypt on Gaza border</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201233290</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Jump-start economy: Give health care to all</td>\n",
       "      <td>False</td>\n",
       "      <td>fadi420</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201274720</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Council of Europe bashes EU&amp;UN terror blacklist</td>\n",
       "      <td>False</td>\n",
       "      <td>mhermans</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_created date_created  up_votes  down_votes  \\\n",
       "0    1201232046   2008-01-25         3           0   \n",
       "1    1201232075   2008-01-25         2           0   \n",
       "2    1201232523   2008-01-25         3           0   \n",
       "3    1201233290   2008-01-25         1           0   \n",
       "4    1201274720   2008-01-25         4           0   \n",
       "\n",
       "                                             title  over_18    author  \\\n",
       "0                Scores killed in Pakistan clashes    False     polar   \n",
       "1                 Japan resumes refuelling mission    False     polar   \n",
       "2                  US presses Egypt on Gaza border    False     polar   \n",
       "3     Jump-start economy: Give health care to all     False   fadi420   \n",
       "4  Council of Europe bashes EU&UN terror blacklist    False  mhermans   \n",
       "\n",
       "    category  \n",
       "0  worldnews  \n",
       "1  worldnews  \n",
       "2  worldnews  \n",
       "3  worldnews  \n",
       "4  worldnews  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 509236 entries, 0 to 509235\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   time_created  509236 non-null  int64 \n",
      " 1   date_created  509236 non-null  object\n",
      " 2   up_votes      509236 non-null  int64 \n",
      " 3   down_votes    509236 non-null  int64 \n",
      " 4   title         509236 non-null  object\n",
      " 5   over_18       509236 non-null  bool  \n",
      " 6   author        509236 non-null  object\n",
      " 7   category      509236 non-null  object\n",
      "dtypes: bool(1), int64(3), object(4)\n",
      "memory usage: 27.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_created    0\n",
       "date_created    0\n",
       "up_votes        0\n",
       "down_votes      0\n",
       "title           0\n",
       "over_18         0\n",
       "author          0\n",
       "category        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for nulls in the dataframe - none detected\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days represented in dataframe: 3223\n",
      "Data date range is from 2008-01-25 to 2016-11-22\n"
     ]
    }
   ],
   "source": [
    "# The data spans 3223 days, from 1/25/08 to 11/22/16\n",
    "print(f\"Number of days represented in dataframe: {len(df['date_created'].unique())}\")\n",
    "print(f\"Data date range is from {min(df['date_created'])} to {max(df['date_created'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## NLP & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to concisely process this dataframe and others in the same format\n",
    "def process_data(df):\n",
    "    \n",
    "    # Redefining the 'time_created' column to hold datetime, converted from unix timestamp format\n",
    "    df['time_created'] = [datetime.fromtimestamp(ts) for ts in df['time_created']]\n",
    "    # Dropping 'date_created' because of redundancy\n",
    "    df.drop(columns='date_created', inplace=True)\n",
    "    \n",
    "    # Dropping 'category' feature if only one category is present\n",
    "    if len(df['category'].unique()) == 1:\n",
    "        df.drop(columns='category', inplace=True)\n",
    "    # Similarly dropping down votes if there are none reported\n",
    "    if sum(df['down_votes']) == 0:\n",
    "        df.drop(columns='down_votes', inplace=True)\n",
    "  \n",
    "\n",
    "    # -----------\n",
    "    # Creating columns of empty lists to hold NLP output\n",
    "    df['noun_phrases'] = df.apply(lambda value: [], axis=1)\n",
    "    df['verbs'] = df.apply(lambda value: [], axis=1)\n",
    "    df['entities'] = df.apply(lambda value: [], axis=1)\n",
    "    df['entity_labels'] = df.apply(lambda value: [], axis=1)\n",
    "    # New column to hold the sentiment analysis results - can assign Null for now since data will be floats\n",
    "    df['compound_sentiment'] = np.NaN\n",
    "    \n",
    "    # Instantiating spacy NLP\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Instantiating Sentiment Intensity Analyzer\n",
    "    sent = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Incorporating the loop from 'title_deconstruct' function to segment post titles into component pieces and insert into original dataframe\n",
    "    for i in range(len(df)):\n",
    "        title = df['title'][i]\n",
    "        doc = nlp(title)\n",
    "        df.at[i, 'noun_phrases'] = [noun_chunk.text for noun_chunk in doc.noun_chunks]\n",
    "        df.at[i, 'verbs'] = [verb.lemma_ for verb in doc if verb.pos_ == \"VERB\"]\n",
    "        df.at[i, 'entities'] = [entity.text for entity in doc.ents]\n",
    "        df.at[i, 'entity_labels'] = [entity.label_ for entity in doc.ents]\n",
    "        \n",
    "        # Sentiment analysis\n",
    "        title_sentiment = sent.polarity_scores(title)\n",
    "        df.at[i, 'compound_sentiment'] = round(title_sentiment['compound'], 2)\n",
    "    # -----------    \n",
    "    \n",
    "    \n",
    "    # Binarizing 'over_18' feature\n",
    "    df['over_18'] = df['over_18'].map({False:0, True:1})\n",
    "    \n",
    "    # Creating a feature to hold the post length in characters and words\n",
    "    df['post_length_chars'] = df['title'].apply(len)\n",
    "    df['post_length_tokens'] = df['title'].str.split().apply(len)\n",
    "    \n",
    "    # Generating features to hold total author posts and total author upvotes alongside each post\n",
    "    df['author_posts'] = df['author'].groupby(df['author']).transform('count')\n",
    "    df['author_upvotes'] = df['up_votes'].groupby(df['author']).transform('sum')\n",
    "    \n",
    "    # Generating a feature to hold day of the week and dummifying\n",
    "    df['weekday'] = df['time_created'].dt.day_name()\n",
    "    day_dummies = pd.get_dummies(df['weekday'], drop_first=True)\n",
    "    df = pd.concat([df, day_dummies], axis=1)\n",
    "    df.drop(columns='weekday', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering columns for legibility\n",
    "df = df[['time_created', 'author', 'author_posts', 'author_upvotes', 'over_18', 'up_votes', 'title', \n",
    "         'compound_sentiment', 'noun_phrases', 'verbs', 'entities', 'entity_labels', 'post_length_chars', \n",
    "         'post_length_tokens', 'Saturday', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>author</th>\n",
       "      <th>author_posts</th>\n",
       "      <th>author_upvotes</th>\n",
       "      <th>over_18</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verbs</th>\n",
       "      <th>entities</th>\n",
       "      <th>entity_labels</th>\n",
       "      <th>post_length_chars</th>\n",
       "      <th>post_length_tokens</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-24 22:34:06</td>\n",
       "      <td>polar</td>\n",
       "      <td>50</td>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>[Scores, Pakistan clashes]</td>\n",
       "      <td>[kill]</td>\n",
       "      <td>[Pakistan]</td>\n",
       "      <td>[GPE]</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-24 22:34:35</td>\n",
       "      <td>polar</td>\n",
       "      <td>50</td>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Japan resumes refuelling mission</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[Japan, refuelling mission]</td>\n",
       "      <td>[resume]</td>\n",
       "      <td>[Japan]</td>\n",
       "      <td>[GPE]</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-24 22:42:03</td>\n",
       "      <td>polar</td>\n",
       "      <td>50</td>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>US presses Egypt on Gaza border</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[US, Egypt, Gaza border]</td>\n",
       "      <td>[press]</td>\n",
       "      <td>[US, Egypt, Gaza]</td>\n",
       "      <td>[GPE, GPE, GPE]</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time_created author  author_posts  author_upvotes  over_18  up_votes  \\\n",
       "0 2008-01-24 22:34:06  polar            50            1151        0         3   \n",
       "1 2008-01-24 22:34:35  polar            50            1151        0         2   \n",
       "2 2008-01-24 22:42:03  polar            50            1151        0         3   \n",
       "\n",
       "                               title  compound_sentiment  \\\n",
       "0  Scores killed in Pakistan clashes               -0.67   \n",
       "1   Japan resumes refuelling mission                0.00   \n",
       "2    US presses Egypt on Gaza border                0.00   \n",
       "\n",
       "                  noun_phrases     verbs           entities    entity_labels  \\\n",
       "0   [Scores, Pakistan clashes]    [kill]         [Pakistan]            [GPE]   \n",
       "1  [Japan, refuelling mission]  [resume]            [Japan]            [GPE]   \n",
       "2     [US, Egypt, Gaza border]   [press]  [US, Egypt, Gaza]  [GPE, GPE, GPE]   \n",
       "\n",
       "   post_length_chars  post_length_tokens  Saturday  Sunday  Monday  Tuesday  \\\n",
       "0                 33                   5         0       0       0        0   \n",
       "1                 32                   4         0       0       0        0   \n",
       "2                 31                   6         0       0       0        0   \n",
       "\n",
       "   Wednesday  Thursday  \n",
       "0          0         1  \n",
       "1          0         1  \n",
       "2          0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509236, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/world_news_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/world_news_processed.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509236, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 509236 entries, 0 to 509235\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   time_created        509236 non-null  datetime64[ns]\n",
      " 1   author              509236 non-null  object        \n",
      " 2   author_posts        509236 non-null  int64         \n",
      " 3   author_upvotes      509236 non-null  int64         \n",
      " 4   over_18             509236 non-null  int64         \n",
      " 5   up_votes            509236 non-null  int64         \n",
      " 6   title               509236 non-null  object        \n",
      " 7   compound_sentiment  509236 non-null  float64       \n",
      " 8   noun_phrases        509236 non-null  object        \n",
      " 9   verbs               509236 non-null  object        \n",
      " 10  entities            509236 non-null  object        \n",
      " 11  entity_labels       509236 non-null  object        \n",
      " 12  post_length_chars   509236 non-null  int64         \n",
      " 13  post_length_tokens  509236 non-null  int64         \n",
      " 14  Saturday            509236 non-null  uint8         \n",
      " 15  Sunday              509236 non-null  uint8         \n",
      " 16  Monday              509236 non-null  uint8         \n",
      " 17  Tuesday             509236 non-null  uint8         \n",
      " 18  Wednesday           509236 non-null  uint8         \n",
      " 19  Thursday            509236 non-null  uint8         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(6), object(6), uint8(6)\n",
      "memory usage: 57.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    509236.000000\n",
       "mean        112.236283\n",
       "std         541.694675\n",
       "min           0.000000\n",
       "25%           1.000000\n",
       "50%           5.000000\n",
       "75%          16.000000\n",
       "max       21253.000000\n",
       "Name: up_votes, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary stats for upvotes\n",
    "df['up_votes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Looking at titles of most upvoted posts\n",
    "# df['up_votes'].groupby(df['title']).sum().sort_values(ascending=False)[0:10].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>author</th>\n",
       "      <th>author_posts</th>\n",
       "      <th>author_upvotes</th>\n",
       "      <th>over_18</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verbs</th>\n",
       "      <th>entities</th>\n",
       "      <th>entity_labels</th>\n",
       "      <th>post_length_chars</th>\n",
       "      <th>post_length_tokens</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377200</th>\n",
       "      <td>2015-06-20 12:41:11</td>\n",
       "      <td>KRISHNA53</td>\n",
       "      <td>109</td>\n",
       "      <td>75492</td>\n",
       "      <td>0</td>\n",
       "      <td>21253</td>\n",
       "      <td>A biotech startup has managed to 3-D print fak...</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>[A biotech startup, 3-D print fake rhino horns...</td>\n",
       "      <td>[manage, carry, plan, flood, undercut, get, fo...</td>\n",
       "      <td>[Chinese, one-eighth]</td>\n",
       "      <td>[NORP, CARDINAL]</td>\n",
       "      <td>289</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391415</th>\n",
       "      <td>2015-08-24 08:57:59</td>\n",
       "      <td>joeyoungblood</td>\n",
       "      <td>3</td>\n",
       "      <td>13525</td>\n",
       "      <td>0</td>\n",
       "      <td>13435</td>\n",
       "      <td>Twitter has forced 30 websites that archive po...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>[Twitter, 30 websites, archive politician s de...</td>\n",
       "      <td>[force, delete, shut, remove, keep]</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[CARDINAL]</td>\n",
       "      <td>139</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450818</th>\n",
       "      <td>2016-04-03 14:01:46</td>\n",
       "      <td>mister_geaux</td>\n",
       "      <td>12</td>\n",
       "      <td>22292</td>\n",
       "      <td>0</td>\n",
       "      <td>13244</td>\n",
       "      <td>2.6 terabyte leak of Panamanian shell company ...</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>[2.6 terabyte leak, Panamanian shell company d...</td>\n",
       "      <td>[reveal, lead, manage]</td>\n",
       "      <td>[2.6, Panamanian, Fifa]</td>\n",
       "      <td>[CARDINAL, NORP, ORG]</td>\n",
       "      <td>277</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391318</th>\n",
       "      <td>2015-08-23 18:09:28</td>\n",
       "      <td>navysealassulter</td>\n",
       "      <td>1</td>\n",
       "      <td>12333</td>\n",
       "      <td>0</td>\n",
       "      <td>12333</td>\n",
       "      <td>The police officer who leaked the footage of t...</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>[The police officer, who, the footage, the sur...</td>\n",
       "      <td>[leak, paradise, wash, charge, bring, do, get]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>243</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390252</th>\n",
       "      <td>2015-08-18 19:06:08</td>\n",
       "      <td>seapiglet</td>\n",
       "      <td>1</td>\n",
       "      <td>11288</td>\n",
       "      <td>0</td>\n",
       "      <td>11288</td>\n",
       "      <td>Paris shooting survivor suing French media for...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>[Paris, survivor, French media, his location, ...</td>\n",
       "      <td>[shoot, sue, give, hide]</td>\n",
       "      <td>[Paris, French]</td>\n",
       "      <td>[GPE, NORP]</td>\n",
       "      <td>98</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449809</th>\n",
       "      <td>2016-03-30 07:19:33</td>\n",
       "      <td>Xiroth</td>\n",
       "      <td>2</td>\n",
       "      <td>11108</td>\n",
       "      <td>0</td>\n",
       "      <td>11108</td>\n",
       "      <td>Hundreds of thousands of leaked emails reveal ...</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>[Hundreds of thousands, leaked emails, massive...</td>\n",
       "      <td>[leak, reveal]</td>\n",
       "      <td>[Hundreds of thousands]</td>\n",
       "      <td>[CARDINAL]</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397215</th>\n",
       "      <td>2015-09-17 20:14:48</td>\n",
       "      <td>DoremusJessup</td>\n",
       "      <td>5037</td>\n",
       "      <td>584380</td>\n",
       "      <td>0</td>\n",
       "      <td>10922</td>\n",
       "      <td>Brazil s Supreme Court has banned corporate co...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>[Brazil s Supreme Court, corporate contributio...</td>\n",
       "      <td>[ban]</td>\n",
       "      <td>[Brazil, Supreme Court]</td>\n",
       "      <td>[GPE, ORG]</td>\n",
       "      <td>92</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390494</th>\n",
       "      <td>2015-08-19 20:30:33</td>\n",
       "      <td>DawgsOnTopUGA</td>\n",
       "      <td>1</td>\n",
       "      <td>10515</td>\n",
       "      <td>0</td>\n",
       "      <td>10515</td>\n",
       "      <td>ISIS beheads 81-year-old pioneer archaeologist...</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>[ISIS, 81-year-old pioneer archaeologist, fore...</td>\n",
       "      <td>[behead, hold, refuse, tell]</td>\n",
       "      <td>[ISIS, 81-year-old, Syria, 1 month, ISIS, Palm...</td>\n",
       "      <td>[ORG, DATE, GPE, DATE, ORG, PRODUCT]</td>\n",
       "      <td>188</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500786</th>\n",
       "      <td>2016-10-19 08:47:15</td>\n",
       "      <td>mvea</td>\n",
       "      <td>18</td>\n",
       "      <td>22988</td>\n",
       "      <td>0</td>\n",
       "      <td>10394</td>\n",
       "      <td>Feeding cows seaweed could slash global greenh...</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>[Feeding cows, global greenhouse gas emissions...</td>\n",
       "      <td>[slash, say, discover, add, dry, reduce, produce]</td>\n",
       "      <td>[up to]</td>\n",
       "      <td>[CARDINAL]</td>\n",
       "      <td>225</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388230</th>\n",
       "      <td>2015-08-07 11:58:55</td>\n",
       "      <td>fiffers</td>\n",
       "      <td>5</td>\n",
       "      <td>12092</td>\n",
       "      <td>0</td>\n",
       "      <td>10377</td>\n",
       "      <td>Brazilian radio host famous for exposing corru...</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>[Brazilian radio host, corruption, his city, t...</td>\n",
       "      <td>[expose, murder, broadcast]</td>\n",
       "      <td>[Brazilian, two]</td>\n",
       "      <td>[NORP, CARDINAL]</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              time_created            author  author_posts  author_upvotes  \\\n",
       "377200 2015-06-20 12:41:11         KRISHNA53           109           75492   \n",
       "391415 2015-08-24 08:57:59     joeyoungblood             3           13525   \n",
       "450818 2016-04-03 14:01:46      mister_geaux            12           22292   \n",
       "391318 2015-08-23 18:09:28  navysealassulter             1           12333   \n",
       "390252 2015-08-18 19:06:08         seapiglet             1           11288   \n",
       "449809 2016-03-30 07:19:33            Xiroth             2           11108   \n",
       "397215 2015-09-17 20:14:48     DoremusJessup          5037          584380   \n",
       "390494 2015-08-19 20:30:33     DawgsOnTopUGA             1           10515   \n",
       "500786 2016-10-19 08:47:15              mvea            18           22988   \n",
       "388230 2015-08-07 11:58:55           fiffers             5           12092   \n",
       "\n",
       "        over_18  up_votes                                              title  \\\n",
       "377200        0     21253  A biotech startup has managed to 3-D print fak...   \n",
       "391415        0     13435  Twitter has forced 30 websites that archive po...   \n",
       "450818        0     13244  2.6 terabyte leak of Panamanian shell company ...   \n",
       "391318        0     12333  The police officer who leaked the footage of t...   \n",
       "390252        0     11288  Paris shooting survivor suing French media for...   \n",
       "449809        0     11108  Hundreds of thousands of leaked emails reveal ...   \n",
       "397215        0     10922  Brazil s Supreme Court has banned corporate co...   \n",
       "390494        0     10515  ISIS beheads 81-year-old pioneer archaeologist...   \n",
       "500786        0     10394  Feeding cows seaweed could slash global greenh...   \n",
       "388230        0     10377  Brazilian radio host famous for exposing corru...   \n",
       "\n",
       "        compound_sentiment                                       noun_phrases  \\\n",
       "377200               -0.20  [A biotech startup, 3-D print fake rhino horns...   \n",
       "391415                0.53  [Twitter, 30 websites, archive politician s de...   \n",
       "450818               -0.64  [2.6 terabyte leak, Panamanian shell company d...   \n",
       "391318               -0.64  [The police officer, who, the footage, the sur...   \n",
       "390252                0.34  [Paris, survivor, French media, his location, ...   \n",
       "449809               -0.32  [Hundreds of thousands, leaked emails, massive...   \n",
       "397215                0.51  [Brazil s Supreme Court, corporate contributio...   \n",
       "390494               -0.51  [ISIS, 81-year-old pioneer archaeologist, fore...   \n",
       "500786               -0.27  [Feeding cows, global greenhouse gas emissions...   \n",
       "388230               -0.76  [Brazilian radio host, corruption, his city, t...   \n",
       "\n",
       "                                                    verbs  \\\n",
       "377200  [manage, carry, plan, flood, undercut, get, fo...   \n",
       "391415                [force, delete, shut, remove, keep]   \n",
       "450818                             [reveal, lead, manage]   \n",
       "391318     [leak, paradise, wash, charge, bring, do, get]   \n",
       "390252                           [shoot, sue, give, hide]   \n",
       "449809                                     [leak, reveal]   \n",
       "397215                                              [ban]   \n",
       "390494                       [behead, hold, refuse, tell]   \n",
       "500786  [slash, say, discover, add, dry, reduce, produce]   \n",
       "388230                        [expose, murder, broadcast]   \n",
       "\n",
       "                                                 entities  \\\n",
       "377200                              [Chinese, one-eighth]   \n",
       "391415                                               [30]   \n",
       "450818                            [2.6, Panamanian, Fifa]   \n",
       "391318                                                 []   \n",
       "390252                                    [Paris, French]   \n",
       "449809                            [Hundreds of thousands]   \n",
       "397215                            [Brazil, Supreme Court]   \n",
       "390494  [ISIS, 81-year-old, Syria, 1 month, ISIS, Palm...   \n",
       "500786                                            [up to]   \n",
       "388230                                   [Brazilian, two]   \n",
       "\n",
       "                               entity_labels  post_length_chars  \\\n",
       "377200                      [NORP, CARDINAL]                289   \n",
       "391415                            [CARDINAL]                139   \n",
       "450818                 [CARDINAL, NORP, ORG]                277   \n",
       "391318                                    []                243   \n",
       "390252                           [GPE, NORP]                 98   \n",
       "449809                            [CARDINAL]                100   \n",
       "397215                            [GPE, ORG]                 92   \n",
       "390494  [ORG, DATE, GPE, DATE, ORG, PRODUCT]                188   \n",
       "500786                            [CARDINAL]                225   \n",
       "388230                      [NORP, CARDINAL]                122   \n",
       "\n",
       "        post_length_tokens  Saturday  Sunday  Monday  Tuesday  Wednesday  \\\n",
       "377200                  49         1       0       0        0          0   \n",
       "391415                  22         0       0       1        0          0   \n",
       "450818                  39         0       1       0        0          0   \n",
       "391318                  40         0       1       0        0          0   \n",
       "390252                  16         0       0       0        1          0   \n",
       "449809                  14         0       0       0        0          1   \n",
       "397215                  13         0       0       0        0          0   \n",
       "390494                  30         0       0       0        0          1   \n",
       "500786                  40         0       0       0        0          1   \n",
       "388230                  20         0       0       0        0          0   \n",
       "\n",
       "        Thursday  \n",
       "377200         0  \n",
       "391415         0  \n",
       "450818         0  \n",
       "391318         0  \n",
       "390252         0  \n",
       "449809         0  \n",
       "397215         1  \n",
       "390494         0  \n",
       "500786         0  \n",
       "388230         0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('up_votes', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>author</th>\n",
       "      <th>author_posts</th>\n",
       "      <th>author_upvotes</th>\n",
       "      <th>over_18</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verbs</th>\n",
       "      <th>entities</th>\n",
       "      <th>entity_labels</th>\n",
       "      <th>post_length_chars</th>\n",
       "      <th>post_length_tokens</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-24 22:34:06</td>\n",
       "      <td>polar</td>\n",
       "      <td>50</td>\n",
       "      <td>1151</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>[Scores, Pakistan clashes]</td>\n",
       "      <td>[kill]</td>\n",
       "      <td>[Pakistan]</td>\n",
       "      <td>[GPE]</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time_created author  author_posts  author_upvotes  over_18  up_votes  \\\n",
       "0 2008-01-24 22:34:06  polar            50            1151        0         3   \n",
       "\n",
       "                               title  compound_sentiment  \\\n",
       "0  Scores killed in Pakistan clashes               -0.67   \n",
       "\n",
       "                 noun_phrases   verbs    entities entity_labels  \\\n",
       "0  [Scores, Pakistan clashes]  [kill]  [Pakistan]         [GPE]   \n",
       "\n",
       "   post_length_chars  post_length_tokens  Saturday  Sunday  Monday  Tuesday  \\\n",
       "0                 33                   5         0       0       0        0   \n",
       "\n",
       "   Wednesday  Thursday  \n",
       "0          0         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique authors: 85838\n",
      "-----\n",
      "Top 20 contributors by post count: \n",
      "davidreiss666         8897\n",
      "anutensil             5730\n",
      "DoremusJessup         5037\n",
      "maxwellhill           4023\n",
      "igeldard              4013\n",
      "readerseven           3170\n",
      "twolf1                2923\n",
      "madam1                2658\n",
      "nimobo                2564\n",
      "madazzahatter         2503\n",
      "ionised               2493\n",
      "NinjaDiscoJesus       2448\n",
      "bridgesfreezefirst    2405\n",
      "SolInvictus           2181\n",
      "Libertatea            2108\n",
      "vigorous              2077\n",
      "galt1776              1897\n",
      "DougBolivar           1770\n",
      "bob21doh              1698\n",
      "trot-trot             1649\n",
      "Name: author, dtype: int64\n",
      "-----\n",
      "Top 20 contributors by upvotes: \n",
      "author\n",
      "maxwellhill         1985416\n",
      "anutensil           1531544\n",
      "Libertatea           832102\n",
      "DoremusJessup        584380\n",
      "Wagamaga             580121\n",
      "NinjaDiscoJesus      492582\n",
      "madazzahatter        428966\n",
      "madam1               390541\n",
      "davidreiss666        338306\n",
      "kulkke               333311\n",
      "pnewell              297270\n",
      "nimobo               266733\n",
      "trot-trot            258367\n",
      "ionised              256159\n",
      "EightRoundsRapid     254670\n",
      "twolf1               230031\n",
      "mepper               223369\n",
      "PanAfrica            219742\n",
      "readerseven          209225\n",
      "green_flash          205554\n",
      "Name: up_votes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique authors: {len(df['author'].unique())}\")\n",
    "print('-----')\n",
    "print(f\"Top 20 contributors by post count: \\n{df['author'].value_counts()[0:20]}\")\n",
    "print('-----')\n",
    "print(f\"Top 20 contributors by upvotes: \\n{df['up_votes'].groupby(df['author']).sum().sort_values(ascending=False)[0:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    508916\n",
      "1       320\n",
      "Name: over_18, dtype: int64\n",
      "0    0.999372\n",
      "1    0.000628\n",
      "Name: over_18, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Looking at distribution of 'over_18' posts by number and percentage\n",
    "print(df['over_18'].value_counts())\n",
    "print(df['over_18'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>author</th>\n",
       "      <th>author_posts</th>\n",
       "      <th>author_upvotes</th>\n",
       "      <th>over_18</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verbs</th>\n",
       "      <th>entities</th>\n",
       "      <th>entity_labels</th>\n",
       "      <th>post_length_chars</th>\n",
       "      <th>post_length_tokens</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>2008-03-24 13:57:18</td>\n",
       "      <td>pressed</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>Pics from the Tibetan protests - more graphic ...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>[Pics, the Tibetan protests, Wikileaks, nsfw]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Tibetan]</td>\n",
       "      <td>[NORP]</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>2008-05-18 15:25:18</td>\n",
       "      <td>alllie</td>\n",
       "      <td>1092</td>\n",
       "      <td>60210</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>MI5 linked to Max Mosley’s Nazi-style, sadomas...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>[MI5, Max Mosley’s Nazi-style, sadomasochistic...</td>\n",
       "      <td>[link, lead]</td>\n",
       "      <td>[Max Mosley’s, Nazi, the British Union of Fasc...</td>\n",
       "      <td>[PERSON, NORP, ORG, DATE]</td>\n",
       "      <td>188</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8414</th>\n",
       "      <td>2008-06-05 15:42:05</td>\n",
       "      <td>stesch</td>\n",
       "      <td>211</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tabloid Horrifies Germany: Poland s Yellow Pre...</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>[Poland s Yellow Press, Blood Red, you, the li...</td>\n",
       "      <td>[turn, follow]</td>\n",
       "      <td>[Tabloid Horrifies Germany, Poland, Yellow Pre...</td>\n",
       "      <td>[PERSON, GPE, ORG, ORDINAL, ORG, GPE]</td>\n",
       "      <td>135</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time_created   author  author_posts  author_upvotes  over_18  \\\n",
       "1885 2008-03-24 13:57:18  pressed             1             189        1   \n",
       "6721 2008-05-18 15:25:18   alllie          1092           60210        1   \n",
       "8414 2008-06-05 15:42:05   stesch           211            1992        1   \n",
       "\n",
       "      up_votes                                              title  \\\n",
       "1885       189  Pics from the Tibetan protests - more graphic ...   \n",
       "6721         5  MI5 linked to Max Mosley’s Nazi-style, sadomas...   \n",
       "8414         0  Tabloid Horrifies Germany: Poland s Yellow Pre...   \n",
       "\n",
       "      compound_sentiment                                       noun_phrases  \\\n",
       "1885               -0.23      [Pics, the Tibetan protests, Wikileaks, nsfw]   \n",
       "6721                0.73  [MI5, Max Mosley’s Nazi-style, sadomasochistic...   \n",
       "8414               -0.60  [Poland s Yellow Press, Blood Red, you, the li...   \n",
       "\n",
       "               verbs                                           entities  \\\n",
       "1885              []                                          [Tibetan]   \n",
       "6721    [link, lead]  [Max Mosley’s, Nazi, the British Union of Fasc...   \n",
       "8414  [turn, follow]  [Tabloid Horrifies Germany, Poland, Yellow Pre...   \n",
       "\n",
       "                              entity_labels  post_length_chars  \\\n",
       "1885                                 [NORP]                 76   \n",
       "6721              [PERSON, NORP, ORG, DATE]                188   \n",
       "8414  [PERSON, GPE, ORG, ORDINAL, ORG, GPE]                135   \n",
       "\n",
       "      post_length_tokens  Saturday  Sunday  Monday  Tuesday  Wednesday  \\\n",
       "1885                  12         0       0       1        0          0   \n",
       "6721                  31         0       1       0        0          0   \n",
       "8414                  25         0       0       0        0          0   \n",
       "\n",
       "      Thursday  \n",
       "1885         0  \n",
       "6721         0  \n",
       "8414         1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at data for a sample of the posts classified as \"over_18\" - on fist look, lots of violent content\n",
    "df[df['over_18'] == True].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a new dataframe of the over_18 posts and examining most upvoted among those\n",
    "# nsfw = df[df['over_18'] == True]\n",
    "# nsfw.sort_values(by='up_votes', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
